# CÃ“DIGO COMPLETO E CORRIGIDO PARA: app/services/llm_service.py
# (Implementa o Agente de MÃºltiplas Etapas com Parallel Tool Calls)

import os
import json
import pytz
from datetime import datetime
from openai import OpenAI
from typing import List, Dict, Any, Optional, Iterator

class LLMService:
    def __init__(self, api_key: str = None, model: str = "gpt-4o-mini"):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("Chave da API OpenAI nÃ£o fornecida")
        
        self.routing_model = "gpt-4o-mini"
        self.generation_model = model 
        
        self.client = OpenAI(api_key=self.api_key)
        self.token_usage = {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}

        # --- ARQUITETURA DE FERRAMENTAS ROBUSTA ---
        self.tool_ingest = {
            "type": "function",
            "function": {
                "name": "call_ingest_tool",
                "description": (
                    "Usado quando o usuÃ¡rio quer ingerir, re-ingerir ou atualizar o Ã­ndice RAG "
                    "de um repositÃ³rio GitHub. "
                    "Serve para a primeira ingestÃ£o, para atualizar dados apÃ³s novas alteraÃ§Ãµes "
                    "ou para garantir que o Ã­ndice esteja sincronizado antes de consultas, "
                    "relatÃ³rios ou agendamentos."
                ),
                "parameters": {
                    "type": "object",
                    "properties": {
                        "repositorio": {
                            "type": "string",
                            "description": (
                                "O nome do repositÃ³rio no formato 'usuario/nome'. "
                                "Nunca invente esse valor. Se nÃ£o for fornecido, peÃ§a esclarecimento."
                            )
                        }
                    },
                    "required": ["repositorio"],
                },
            },
        }
        
        self.tool_query = {
            "type": "function",
            "function": {
                "name": "call_query_tool",
                "description": (
                    "Usado para perguntas sobre um repositÃ³rio (RAG). "
                    "Ideal para dÃºvidas pontuais sobre requisitos, commits, PRs, issues, "
                    "design de mÃ³dulos, histÃ³rico de mudanÃ§as, impactos, rastreabilidade etc. "
                    "A resposta aparecerÃ¡ diretamente na interface de chat, nÃ£o como arquivo."
                ),
                "parameters": {
                    "type": "object",
                    "properties": {
                        "repositorio": {
                            "type": "string",
                            "description": (
                                "O nome do repositÃ³rio no formato 'usuario/nome'. "
                                "Nunca invente esse valor. Se nÃ£o for fornecido, peÃ§a esclarecimento."
                            )
                        },
                        "prompt_usuario": {
                            "type": "string",
                            "description": (
                                "A pergunta especÃ­fica do usuÃ¡rio. "
                                "Inclua aqui detalhes de escopo: requisito(s), mÃ³dulo(s), branch, "
                                "intervalo de tempo, tipo de artefato (commits, PRs, issues), etc."
                            )
                        }
                    },
                    "required": ["repositorio", "prompt_usuario"],
                },
            },
        }

        self.tool_report = {
            "type": "function",
            "function": {
                "name": "call_report_tool",
                "description": (
                    "Usado para pedir um 'relatÃ³rio' ou 'grÃ¡fico' para DOWNLOAD IMEDIATO "
                    "(salvar o arquivo no computador). "
                    "Exemplos: relatÃ³rio de rastreabilidade de requisitos, mapa de impacto de PRs, "
                    "resumo da sprint, estatÃ­sticas de commits por autor/arquivo, "
                    "exportar dados para planilha. "
                    "Nunca use esta ferramenta para envios por e-mail."
                ),
                "parameters": {
                    "type": "object",
                    "properties": {
                        "repositorio": {
                            "type": "string",
                            "description": (
                                "O nome do repositÃ³rio no formato 'usuario/nome'. "
                                "Nunca invente esse valor."
                            )
                        },
                        "prompt_usuario": {
                            "type": "string",
                            "description": (
                                "A instruÃ§Ã£o para o relatÃ³rio. "
                                "Descreva claramente o tipo de anÃ¡lise desejada "
                                "(por exemplo: rastreabilidade de requisito X, comparaÃ§Ã£o entre releases, "
                                "mÃ©tricas de PR, hotspots de cÃ³digo, etc.)."
                            )
                        }
                    },
                    "required": ["repositorio", "prompt_usuario"],
                },
            },
        }

        self.tool_schedule = {
            "type": "function",
            "function": {
                "name": "call_schedule_tool",
                "description": (
                    "Usado quando o usuÃ¡rio quer ENVIAR um relatÃ³rio por EMAIL (agora ou agendado). "
                    "Use sempre que 'email', 'e-mail', 'agendar', 'alerta', 'monitorar', "
                    "'todo dia', 'toda semana', 'todo mÃªs' ou 'enviar para mim' for mencionado. "
                    "Ideal para monitorar requisitos, mÃ³dulos crÃ­ticos, qualidade de cÃ³digo e "
                    "evoluÃ§Ã£o do projeto ao longo do tempo."
                ),
                "parameters": {
                    "type": "object",
                    "properties": {
                        "repositorio": {
                            "type": "string",
                            "description": "O nome do repositÃ³rio no formato 'usuario/nome'."
                        },
                        "prompt_relatorio": {
                            "type": "string",
                            "description": (
                                "O que o relatÃ³rio deve conter. "
                                "Descreva o objetivo do relatÃ³rio e o foco de rastreabilidade "
                                "ou mÃ©tricas que devem ser monitoradas."
                            )
                        },
                        "frequencia": {
                            "type": "string",
                            "enum": ["once", "daily", "weekly", "monthly"],
                            "description": (
                                "A frequÃªncia. Use 'once' para envio imediato. "
                                "'daily' para diÃ¡rio, 'weekly' para semanal, 'monthly' para mensal."
                            )
                        },
                        "hora": {
                            "type": "string",
                            "description": "A hora no formato HH:MM (24h)."
                        },
                        "timezone": {
                            "type": "string",
                            "description": "O fuso horÃ¡rio (ex: 'America/Sao_Paulo')."
                        },
                        "user_email": {
                            "type": "string",
                            "description": "O email do destinatÃ¡rio (ex: usuario@gmail.com)."
                        }
                    },
                    "required": ["repositorio", "prompt_relatorio", "frequencia", "hora", "timezone"], 
                },
            },
        }
        
        self.tool_save_instruction = {
            "type": "function",
            "function": {
                "name": "call_save_instruction_tool",
                "description": (
                    "Usado para salvar uma instruÃ§Ã£o para futuros relatÃ³rios. "
                    "Ideal quando o usuÃ¡rio quer registrar um 'template' de anÃ¡lise, "
                    "como por exemplo: 'relatÃ³rio de rastreabilidade do requisito X', "
                    "'relatÃ³rio de qualidade de PRs da equipe Y', etc."
                ),
                "parameters": {
                    "type": "object",
                    "properties": {
                        "repositorio": {
                            "type": "string",
                            "description": (
                                "O repositÃ³rio ao qual esta instruÃ§Ã£o se aplica. "
                                "Formato 'usuario/nome'."
                            )
                        },
                        "instrucao": {
                            "type": "string",
                            "description": (
                                "A instruÃ§Ã£o especÃ­fica que o usuÃ¡rio quer salvar. "
                                "Descreva de forma reutilizÃ¡vel, pois serÃ¡ usada em execuÃ§Ãµes futuras."
                            )
                        }
                    },
                    "required": ["repositorio", "instrucao"],
                },
            },
        }

        self.tool_chat = {
            "type": "function",
            "function": {
                "name": "call_chat_tool",
                "description": (
                    "Usado para bate-papo casual, saudaÃ§Ãµes, explicaÃ§Ãµes conceituais ou "
                    "respostas curtas que NÃƒO exigem acesso aos dados do repositÃ³rio. "
                    "Exemplos: explicar o que Ã© GitRAG, RAG, rastreabilidade, como usar a extensÃ£o, "
                    "ajudar a formular uma pergunta melhor, onboarding do usuÃ¡rio, etc."
                ),
                "parameters": {
                    "type": "object",
                    "properties": {
                        "prompt": {
                            "type": "string",
                            "description": "O texto do usuÃ¡rio."
                        }
                    },
                },
            },
        }

        self.tools = [
            self.tool_ingest,
            self.tool_query,
            self.tool_report,
            self.tool_schedule,
            self.tool_save_instruction,
            self.tool_chat
        ]

        self.tool_map = {
            "call_ingest_tool": self.tool_ingest,
            "call_query_tool": self.tool_query,
            "call_report_tool": self.tool_report,
            "call_schedule_tool": self.tool_schedule,
            "call_save_instruction_tool": self.tool_save_instruction,
            "call_chat_tool": self.tool_chat
        }

    
    def get_intent(self, user_query: str) -> Dict[str, Any]:
        """
        Orquestra o roteamento. Agora retorna UMA ou MAIS ferramentas encadeadas.
        """
        if not self.client:
            raise Exception("LLMService nÃ£o inicializado")
        
        print(f"[LLMService] Iniciando Agente de Encadeamento para: '{user_query}'")
        
        # 1. Ajuste do prompt do sistema para o Agente
        system_prompt = f"""
VocÃª Ã© o Orquestrador de Tarefas da plataforma GitRAG, uma soluÃ§Ã£o de Engenharia de Software
que utiliza IA + RAG para rastreabilidade e anÃ¡lise de requisitos em repositÃ³rios GitHub.

Sua funÃ§Ã£o Ã© LER o pedido do usuÃ¡rio e devolvÃª-lo como uma LISTA ORDENADA de chamadas de ferramentas
(steps), na sequÃªncia correta, com todos os argumentos necessÃ¡rios.

CONTEXTUALIZAÃ‡ÃƒO DA PLATAFORMA:
- O GitRAG trabalha com artefatos de desenvolvimento (cÃ³digo-fonte, commits, Pull Requests, Issues, tags, releases)
  como uma 'documentaÃ§Ã£o viva' consultÃ¡vel.
- Os objetivos tÃ­picos dos usuÃ¡rios incluem:
  - Entender se um requisito estÃ¡ implementado, onde e por quem.
  - Ver o impacto de um requisito, PR ou issue em diferentes mÃ³dulos.
  - Investigar histÃ³rico de decisÃµes (por meio de commits, PRs e issues).
  - Gerar relatÃ³rios de rastreabilidade, auditoria e qualidade.
  - Agendar relatÃ³rios recorrentes por email para monitorar o projeto ao longo do tempo.
- As ferramentas disponÃ­veis sÃ£o:
  - call_ingest_tool      â†’ ingere/atualiza o Ã­ndice RAG de um repositÃ³rio.
  - call_query_tool       â†’ responde perguntas no chat com base no RAG.
  - call_report_tool      â†’ gera relatÃ³rios/exports para DOWNLOAD imediato.
  - call_schedule_tool    â†’ agenda/manda relatÃ³rios por EMAIL (uma vez ou recorrente).
  - call_save_instruction_tool â†’ salva templates de instruÃ§Ã£o para relatÃ³rios futuros.
  - call_chat_tool        â†’ conversa casual, onboarding e explicaÃ§Ãµes que nÃ£o exigem dados do repo.

REGRAS CRÃTICAS DE ENCAMINHAMENTO:
1. CHAME MÃšLTIPLAS FERRAMENTAS QUANDO NECESSÃRIO:
   - Se o usuÃ¡rio pedir 'ingira X e depois gere relatÃ³rio', retorne steps em ordem:
     [call_ingest_tool, call_report_tool].
   - Se o usuÃ¡rio pedir 'ingira X e depois responda minha pergunta', retorne:
     [call_ingest_tool, call_query_tool].
   - Se o usuÃ¡rio pedir 'ingira X, salve um template de relatÃ³rio e agende por email', retorne:
     [call_ingest_tool, call_save_instruction_tool, call_schedule_tool].

2. EMAIL vs DOWNLOAD:
   - Use APENAS call_schedule_tool para qualquer solicitaÃ§Ã£o que mencione explicitamente:
     'email', 'e-mail', 'agendar', 'todo dia', 'toda semana', 'todo mÃªs', 'alerta',
     'monitorar', 'mandar para mim por email'.
   - Use APENAS call_report_tool quando o usuÃ¡rio quiser gerar algo para download imediato:
     'gerar relatÃ³rio', 'gerar grÃ¡fico', 'exportar', 'baixar', 'download', 'PDF', 'planilha', etc.

3. INGESTÃƒO PRÃ‰VIA:
   - Se o usuÃ¡rio pedir consulta (call_query_tool), relatÃ³rio (call_report_tool) ou agendamento
     (call_schedule_tool) para um repositÃ³rio, inclua **call_ingest_tool** como o PRIMEIRO passo,
     exceto se o usuÃ¡rio deixar claro que o repositÃ³rio jÃ¡ foi ingerido e que ele quer apenas
     'reusar' o Ã­ndice existente.
   - Quando em dÃºvida, prefira incluir call_ingest_tool como primeiro passo.

4. CHAT GERAL / ONBOARDING:
   - Se o usuÃ¡rio sÃ³ estiver:
     - cumprimentando ('oi', 'olÃ¡', 'bom dia'),
     - agradecendo ('valeu', 'obrigado'),
     - pedindo explicaÃ§Ãµes sobre a prÃ³pria plataforma GitRAG, RAG ou conceitos gerais de Git/GitHub,
     e NÃƒO exigir dados do repositÃ³rio,
     â†’ use call_chat_tool (pode ser a Ãºnica ferramenta).
   - NÃƒO chame ferramentas de ingestÃ£o/consulta se a pergunta for apenas conceitual.

5. ESCOLHA ENTRE QUERY, REPORT E SCHEDULE:
   - use call_query_tool para perguntas exploratÃ³rias que o usuÃ¡rio quer responder dentro do chat:
     'explique a implementaÃ§Ã£o do requisito X', 'quais commits mencionam a issue Y?',
     'como o mÃ³dulo A evoluiu ao longo do tempo?', 'liste PRs que tocam o arquivo Z'.
   - use call_report_tool quando o usuÃ¡rio pedir explicitamente um RELATÃ“RIO/GRÃFICO/EXPORT
     para DOWNLOAD AGORA.
   - use call_schedule_tool sempre que houver desejo de ENVIO POR EMAIL ou RECORRÃŠNCIA
     (diÃ¡ria, semanal, mensal).

6. SALVAR INSTRUÃ‡Ã•ES:
   - use call_save_instruction_tool quando o usuÃ¡rio falar coisas como:
     'salvar esse modelo de relatÃ³rio', 'guarde essa instruÃ§Ã£o para usar depois',
     'crie um template de relatÃ³rio de rastreabilidade', etc.
   - Ã‰ comum combinar com call_report_tool ou call_schedule_tool em um plano multi-etapas.

7. VALIDAÃ‡ÃƒO DE ARGUMENTOS:
   - Se um argumento obrigatÃ³rio estiver faltando (como o nome do repositÃ³rio),
     NÃƒO invente valores.
     Em vez disso, retorne uma resposta textual de clarificaÃ§Ã£o (tipo: pedir para o usuÃ¡rio informar).
   - Nunca invente o nome de repositÃ³rio, email ou timezone.

8. IDIOMA:
   - Responda sempre no mesmo idioma do usuÃ¡rio (neste caso, normalmente portuguÃªs).

Data/Hora de referÃªncia: Hoje Ã© {datetime.now(pytz.timezone('America/Sao_Paulo')).strftime('%Y-%m-%d')}.
Fuso horÃ¡rio padrÃ£o para agendamentos: 'America/Sao_Paulo'.
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.routing_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_query}
                ],
                tools=self.tools,
                tool_choice="auto" 
            )
            
            message = response.choices[0].message
            tool_calls = message.tool_calls

            if not tool_calls:
                # A IA decidiu que era um bate-papo simples (retornando apenas texto)
                chat_text = message.content or "Entendido."
                return {
                    "type": "simple_chat", 
                    "response_text": chat_text
                }

            # 2. Processa as chamadas de ferramenta (multi-step ou single-step)
            steps = []
            for call in tool_calls:
                try:
                    args = json.loads(call.function.arguments)
                    steps.append({
                        "intent": call.function.name,
                        "args": args
                    })
                except json.JSONDecodeError:
                    return {
                        "type": "clarify",
                        "response_text": (
                            "A IA falhou em formatar a requisiÃ§Ã£o de ferramenta. "
                            "Por favor, reformule sua solicitaÃ§Ã£o de forma mais direta."
                        )
                    }
            
            # ValidaÃ§Ã£o: Se a IA tentou chamar uma ferramenta mas retornou campos vazios, Ã© falha na intenÃ§Ã£o.
            for step in steps:
                if step["intent"] != "call_chat_tool":
                    func_def = self.tool_map.get(step["intent"], {}).get("function", {})
                    required_params = func_def.get("parameters", {}).get("required", [])
                    
                    for param in required_params:
                        if not step["args"].get(param):
                            return {
                                "type": "clarify",
                                "response_text": (
                                    f"O campo obrigatÃ³rio '{param}' estÃ¡ faltando. "
                                    "Por favor, forneÃ§a esse valor (por exemplo, o nome do repositÃ³rio)."
                                )
                            }

            print(f"[LLMService] IntenÃ§Ãµes detectadas: {len(steps)} etapas.")
            
            return {
                "type": "multi_step", 
                "steps": steps
            }

        except Exception as e:
            print(f"[LLMService] Erro no get_intent multi-step: {e}")
            return {"type": "clarify", "response_text": f"Erro interno ao processar: {e}"}

    
    def generate_response(self, query: str, context: List[Dict[str, Any]]) -> Dict[str, Any]:
        if not self.client:
            raise Exception("LLMService nÃ£o inicializado.")
        print("[LLMService] Iniciando resposta RAG (NÃƒO-Streaming)...")
        
        formatted_context = self._format_context(context)
        
        system_prompt = """
VocÃª Ã© um assistente de IA da plataforma GitRAG, especialista em anÃ¡lise de repositÃ³rios GitHub
com foco em rastreabilidade e anÃ¡lise de requisitos.

OBJETIVO:
- Responder Ã  consulta do usuÃ¡rio usando EXCLUSIVAMENTE o contexto fornecido
  (commits, issues, PRs, arquivos, metadados).
- Ajudar o usuÃ¡rio a entender como os requisitos se relacionam com o cÃ³digo,
  quais artefatos dÃ£o suporte a cada afirmaÃ§Ã£o e quais sÃ£o os possÃ­veis impactos.

REGRAS PRINCIPAIS:
1. Use SOMENTE o contexto fornecido.
   - Se algo nÃ£o estiver no contexto, diga claramente que nÃ£o encontrou evidÃªncias.
   - Nunca invente IDs de requisito, hashes de commit, nÃºmeros de PR, "
     "issues ou arquivos que nÃ£o apareÃ§am no texto do contexto.

2. Estruture a resposta de forma clara e Ãºtil para Engenharia de Software.
   SugestÃ£o de estrutura (quando fizer sentido):
   - VisÃ£o geral da resposta.
   - EvidÃªncias principais (commits, PRs, issues, arquivos relevantes).
   - Impactos/implicaÃ§Ãµes (por exemplo: mÃ³dulos afetados, possÃ­veis riscos).
   - Lacunas e incertezas (o que o contexto nÃ£o cobre).

3. Linguagem:
   - Responda no MESMO idioma da consulta (se a pergunta estiver em portuguÃªs, responda em portuguÃªs).
   - Seja direto, tÃ©cnico o suficiente, mas sem jargÃ£o desnecessÃ¡rio.

4. TransparÃªncia:
   - Se o contexto parece contraditÃ³rio ou incompleto, aponte isso explicitamente.
   - Se houver mÃºltiplas interpretaÃ§Ãµes possÃ­veis, explique as alternativas.

5. Tamanho:
   - Seja conciso, mas completo o bastante para ser Ãºtil.
   - Use parÃ¡grafos curtos e, quando ajudar, listas/bullets.
"""
        user_prompt = (
            f"Contexto (documentos de commits, issues, PRs etc.):\n{formatted_context}\n\n"
            f"Consulta do usuÃ¡rio: \"{query}\"\n\n"
            "Baseado APENAS no contexto acima, responda Ã  consulta seguindo as regras do sistema."
        )

        try:
            response = self.client.chat.completions.create(
                model=self.generation_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.1
            )
            
            usage = response.usage
            if usage:
                self.token_usage["prompt_tokens"] += usage.prompt_tokens
                self.token_usage["completion_tokens"] += usage.completion_tokens
                self.token_usage["total_tokens"] += usage.total_tokens

            response_text = response.choices[0].message.content
            return {"response": response_text, "usage": usage}

        except Exception as e:
            print(f"[LLMService] Erro durante o generate_response: {e}")
            return {"response": f"Erro ao gerar resposta: {e}", "usage": None}

    
    def generate_response_stream(self, query: str, context: List[Dict[str, Any]]) -> Iterator[str]:
        if not self.client:
            raise Exception("LLMService nÃ£o inicializado.")
        print("[LLMService] Iniciando resposta em STREAMING...")
        
        formatted_context = self._format_context(context)
        
        system_prompt = """
VocÃª Ã© um assistente de IA da plataforma GitRAG, especialista em anÃ¡lise de repositÃ³rios GitHub
com foco em rastreabilidade e anÃ¡lise de requisitos.

OBJETIVO:
- Responder Ã  consulta do usuÃ¡rio usando EXCLUSIVAMENTE o contexto fornecido
  (commits, issues, PRs, arquivos, metadados).

Siga as mesmas regras de estilo e transparÃªncia descritas anteriormente:
- Use apenas o contexto.
- NÃ£o invente IDs de requisito, commits ou PRs.
- Estruture a resposta (visÃ£o geral, evidÃªncias, impactos, lacunas) quando fizer sentido.
- Responda no idioma da pergunta, de forma clara e direta.
"""
        user_prompt = (
            f"Contexto (documentos de commits, issues, PRs etc.):\n{formatted_context}\n\n"
            f"Consulta do usuÃ¡rio: \"{query}\"\n\n"
            "Baseado APENAS no contexto acima, responda Ã  consulta seguindo as regras do sistema."
        )

        try:
            stream = self.client.chat.completions.create(
                model=self.generation_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                stream=True,
                temperature=0.1
            )
            for chunk in stream:
                content = chunk.choices[0].delta.content
                if content:
                    yield content
        except Exception as e:
            print(f"[LLMService] Erro durante o streaming: {e}")
            yield f"\n\n**Erro ao gerar resposta:** {e}"

    
    def generate_analytics_report(self, repo_name: str, user_prompt: str, raw_data: List[Dict[str, Any]]) -> str:
        context_json_string = json.dumps(raw_data)
        system_prompt = f"""
VocÃª Ã© um analista de dados especializado em repositÃ³rios de software na plataforma GitRAG.

Sua tarefa Ã© transformar dados brutos de um repositÃ³rio (commits, PRs, issues, arquivos, mÃ©tricas)
em um ÃšNICO objeto JSON com duas chaves principais:

1. "analysis_markdown": texto em Markdown com uma anÃ¡lise interpretativa de alto nÃ­vel.
2. "chart_json": especificaÃ§Ã£o de um grÃ¡fico em formato compatÃ­vel com Chart.js (ou similar).

REGRAS OBRIGATÃ“RIAS:
1. Formato:
   - O resultado FINAL DEVE ser um ÃšNICO objeto JSON vÃ¡lido.
   - NÃ£o escreva texto fora do JSON.

2. Estrutura JSON:
   - "analysis_markdown": string Markdown.
     Recomenda-se a seguinte estrutura (quando fizer sentido):
       # VisÃ£o Geral
       - Explique rapidamente o que os dados parecem mostrar.

       ## Principais MÃ©tricas
       - Destaque nÃºmeros importantes (ex.: nÃºmero de commits, PRs, issues, autores, arquivos mais modificados).

       ## Hotspots e ConcentraÃ§Ã£o
       - Quais arquivos, diretÃ³rios ou mÃ³dulos parecem ser mais modificados?
       - HÃ¡ concentraÃ§Ã£o de conhecimento em poucos autores (risco de bus factor)?

       ## Rastreabilidade de Requisitos
       - Quando possÃ­vel, comente como commits/PRs/issues se relacionam a requisitos (IDs, tags, descriÃ§Ãµes).

       ## Riscos e Pontos de AtenÃ§Ã£o
       - Apresente possÃ­veis riscos (ex.: muitos bugs em um mÃ³dulo, alta rotatividade em arquivos crÃ­ticos).

       ## RecomendaÃ§Ãµes
       - Sugira aÃ§Ãµes prÃ¡ticas (ex.: adicionar testes, refatorar mÃ³dulos, melhorar documentaÃ§Ã£o, etc.).

   - "chart_json": objeto JSON descrevendo UM grÃ¡fico Ãºtil.
     Exemplos de grÃ¡ficos possÃ­veis:
       - Commits por autor.
       - Commits por arquivo ou diretÃ³rio.
       - PRs por estado (aberto/fechado).
       - Issues abertas x fechadas ao longo do tempo.
       - Requisitos (ou tags) mais referenciados.

     O formato pode ser similar ao do Chart.js, por exemplo:
       {{
         "type": "bar",
         "data": {{
           "labels": ["autor1", "autor2"],
           "datasets": [{{
             "label": "Commits por autor",
             "data": [10, 5]
           }}]
         }},
         "options": {{}}
       }}

3. ConsistÃªncia:
   - NÃ£o invente dados. Use SOMENTE o que estiver contido em "Dados Brutos".
   - Se algo nÃ£o estiver disponÃ­vel, ignore ou explique na anÃ¡lise que a informaÃ§Ã£o nÃ£o estÃ¡ presente.

4. Idioma:
   - Produza "analysis_markdown" em portuguÃªs, pois o contexto da plataforma Ã© pt-BR.

5. Tamanho:
   - Seja objetivo, mas informativo. Evite textos extremamente longos.
"""
        final_user_prompt = f"""
Contexto do RepositÃ³rio: {repo_name}
Prompt do UsuÃ¡rio: "{user_prompt}"
Dados Brutos (JSON): {context_json_string}
---
Gere o relatÃ³rio em um Ãºnico objeto JSON com as chaves "analysis_markdown" e "chart_json",
seguindo estritamente as regras fornecidas no sistema.
"""
        try:
            response = self.client.chat.completions.create(
                model=self.generation_model, 
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": final_user_prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.3,
                max_tokens=4000
            )
            
            response_content = response.choices[0].message.content
            
            if not response_content:
                print("[LLMService] ERRO: OpenAI retornou None (provÃ¡vel filtro de conteÃºdo).")
                return json.dumps({
                    "analysis_markdown": (
                        "# Erro de GeraÃ§Ã£o\n\n"
                        "A IA nÃ£o conseguiu gerar uma resposta. Isso pode ter sido causado por filtros de conteÃºdo "
                        "ou uma falha na API."
                    ),
                    "chart_json": None
                })
            
            usage = response.usage
            self.token_usage["prompt_tokens"] += usage.prompt_tokens
            self.token_usage["completion_tokens"] += usage.completion_tokens
            self.token_usage["total_tokens"] += usage.total_tokens
            
            return response_content 

        except Exception as e:
            print(f"[LLMService] Erro ao gerar relatÃ³rio JSON: {e}")
            return json.dumps({
                "analysis_markdown": f"# Erro\n\nNÃ£o foi possÃ­vel gerar a anÃ¡lise: {e}",
                "chart_json": None
            })

    
    def generate_simple_response(self, prompt: str) -> str:
        print(f"[LLMService] Gerando resposta simples para: '{prompt}'")
        
        system_prompt = """
VocÃª Ã© um assistente de IA em modo 'resposta rÃ¡pida' (como um chat de mensageria).

Regras:
- Responda de forma CURTA, casual e prestativa.
- Se o usuÃ¡rio apenas disser 'ok', 'certo', 'beleza', 'show', 'sim', responda com algo simples como 'ğŸ‘' ou 'Entendido.'.
- Se o usuÃ¡rio disser 'obrigado', responda com algo como 'De nada!' ou 'Estou aqui para ajudar!'.
- Se houver uma pergunta simples, responda em 1 ou 2 frases, sem entrar em muitos detalhes tÃ©cnicos.
"""
        try:
            response = self.client.chat.completions.create(
                model=self.routing_model, 
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=50
            )
            return response.choices[0].message.content
        
        except Exception as e:
            print(f"[LLMService] Erro ao gerar resposta simples: {e}")
            return "ğŸ‘" 

    
    def get_token_usage(self) -> Dict[str, int]:
        return self.token_usage

    def _format_context(self, context: List[Dict[str, Any]]) -> str:
        if not context:
            return "Nenhum contexto encontrado."
        
        formatted_text = ""
        for doc in context:
            meta = doc.get('metadata', {})
            tipo = meta.get('type', 'documento')
            conteudo = doc.get('text', '')
            
            formatted_text += f"--- Fonte (Tipo: {tipo}) ---\n"
            if 'url' in meta:
                formatted_text += f"URL: {meta.get('url')}\n"
            if 'autor' in meta:
                formatted_text += f"Autor: {meta.get('autor')}\n"
            if 'titulo' in meta:
                formatted_text += f"TÃ­tulo: {meta.get('titulo')}\n"
                
            formatted_text += f"ConteÃºdo: {conteudo}\n\n"
        
        return formatted_text

    def summarize_plan_for_confirmation(self, steps: List[Dict[str, Any]], user_email: str) -> str:
        """
        Gera uma pergunta de confirmaÃ§Ã£o humanizada baseada no plano de execuÃ§Ã£o.
        (Usa regras determinÃ­sticas para estabilidade e velocidade)
        """
        print(f"[LLMService] Gerando sumÃ¡rio de confirmaÃ§Ã£o para plano de {len(steps)} etapas (Deterministic)...")
        
        plan_summary_list = []
        for step in steps:
            intent = step['intent'].replace('call_', '').replace('_tool', '').capitalize()
            args = step['args']
            
            summary_line = f"* **{intent}:** "

            if intent == 'Ingest':
                summary_line += f"Ingerir o repositÃ³rio **{args.get('repositorio')}** para atualizar o Ã­ndice RAG."
            elif intent == 'Query':
                summary_line += (
                    f"Consultar (RAG) o repositÃ³rio {args.get('repositorio')} "
                    f"com a pergunta: '{args.get('prompt_usuario', '')}'."
                )
            elif intent == 'Report':
                summary_line += (
                    f"Gerar relatÃ³rio para DOWNLOAD do repositÃ³rio {args.get('repositorio')} "
                    f"(Prompt: '{args.get('prompt_usuario', '')}')."
                )
            elif intent == 'Schedule':
                freq = args.get('frequencia')
                repo = args.get('repositorio')
                email = args.get('user_email') or user_email
                hora = args.get('hora')
                tz = args.get('timezone')
                
                if freq == 'once':
                    schedule_details = f"e enviar imediatamente para o email **{email}**"
                else:
                    schedule_details = (
                        f"e agendar com frequÃªncia **{freq}** Ã s {hora} "
                        f"(fuso {tz}) para o email **{email}**"
                    )
                
                summary_line += f"Preparar relatÃ³rio {schedule_details} (Repo: {repo})."
            elif intent == 'Saveinstruction':
                summary_line += (
                    f"Salvar a instruÃ§Ã£o para futuros relatÃ³rios do repositÃ³rio "
                    f"{args.get('repositorio')}."
                )
            
            plan_summary_list.append(summary_line)

        plan_text = "\n".join(plan_summary_list)
        
        confirmation_message = f"""
**Ok, sÃ³ para confirmar o plano de execuÃ§Ã£o ({len(steps)} etapas):**
{plan_text}

As aÃ§Ãµes acima serÃ£o executadas em ordem sequencial (uma depende da anterior).
**Isso estÃ¡ correto?** (Responda 'sim' ou 'nÃ£o')
"""
        return confirmation_message

    def summarize_action_for_confirmation(self, intent_name: str, args: Dict[str, Any]) -> str:
        """
        [MANTIDA] - Gera a confirmaÃ§Ã£o para uma ÃšNICA aÃ§Ã£o de Agendamento Recorrente (Regra de NegÃ³cio Antiga).
        """
        print(f"[LLMService] Gerando sumÃ¡rio de confirmaÃ§Ã£o para agendamento recorrente: {intent_name}...")
        
        # NOTE: Esta funÃ§Ã£o agora lida apenas com o cenÃ¡rio de agendamento recorrente de um passo.
        # Caso 1: Agendamento Recorrente (a Ãºnica aÃ§Ã£o single-step que precisa de confirmaÃ§Ã£o)
        repo = args.get("repositorio")
        prompt = args.get("prompt_relatorio")
        freq = args.get("frequencia")
        hora = args.get("hora")
        tz = args.get("timezone")

        confirmation_text = f"""
Ok, sÃ³ para confirmar: Devo **agendar** o relatÃ³rio para o repositÃ³rio '{repo}' com o prompt: '{prompt[:50]}...',
com frequÃªncia **{freq}**, Ã s **{hora}** (fuso {tz}).

Isso estÃ¡ correto? (Responda 'sim' ou 'nÃ£o')
"""
        return confirmation_text

    def _format_requirements_data(self, requirements_data: List[Dict[str, Any]]) -> str:
        if not requirements_data:
            return "Nenhum dado de requisito fornecido."
        
        return json.dumps(requirements_data, indent=2, ensure_ascii=False)
