import os
import json
import pytz
from datetime import datetime
from openai import OpenAI
from typing import List, Dict, Any, Optional, Iterator

class LLMService:
    def __init__(self, api_key: str = None, model: str = "gpt-4o-mini"):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("Chave da API OpenAI nÃ£o fornecida")
        
        self.routing_model = "gpt-4o-mini"
        self.generation_model = model 
        
        self.client = OpenAI(api_key=self.api_key)
        self.token_usage = {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}

        # --- DEFINIÃ‡ÃƒO DE FERRAMENTAS ---
        
        self.tool_send_onetime_report = {
            "type": "function",
            "function": {
                "name": "call_send_onetime_report_tool",
                "description": "Envia um relatÃ³rio por EMAIL IMEDIATAMENTE.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "repositorio": {"type": "string", "description": "URL completa ou nome do repositÃ³rio."},
                        "prompt_relatorio": {"type": "string", "description": "O assunto do relatÃ³rio."},
                        "email_destino": {"type": "string", "description": "O email para envio."},
                    },
                    "required": ["repositorio", "prompt_relatorio", "email_destino"],
                },
            },
        }

        self.tool_ingest = {
            "type": "function",
            "function": {
                "name": "call_ingest_tool",
                "description": "Ingere/Atualiza o Ã­ndice do repositÃ³rio.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "repositorio": {"type": "string", "description": "A URL completa do GitHub (ex: https://github.com/user/repo/tree/dev) ou apenas user/repo."}
                    },
                    "required": ["repositorio"]
                }
            }
        }
        
        self.tool_query = {
            "type": "function",
            "function": {
                "name": "call_query_tool",
                "description": "Responde perguntas no chat sobre o cÃ³digo.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "repositorio": {"type": "string", "description": "URL ou nome do repositÃ³rio."},
                        "prompt_usuario": {"type": "string", "description": "A pergunta do usuÃ¡rio."}
                    },
                    "required": ["repositorio", "prompt_usuario"],
                },
            },
        }

        self.tool_report = {
            "type": "function",
            "function": {
                "name": "call_report_tool",
                "description": "Gera relatÃ³rio para DOWNLOAD (arquivo).",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "repositorio": {"type": "string", "description": "URL ou nome do repositÃ³rio."},
                        "prompt_usuario": {"type": "string", "description": "DescriÃ§Ã£o do relatÃ³rio."}
                    },
                    "required": ["repositorio", "prompt_usuario"],
                },
            },
        }

        self.tool_schedule = {
            "type": "function",
            "function": {
                "name": "call_schedule_tool",
                "description": "Agenda relatÃ³rios futuros. ATENÃ‡ÃƒO: O usuÃ¡rio fornecerÃ¡ datas em formato brasileiro (dia/mÃªs/ano). Converta SEMPRE para o padrÃ£o ISO YYYY-MM-DD.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "repositorio": {"type": "string", "description": "URL ou nome do repositÃ³rio."},
                        "prompt_relatorio": {"type": "string", "description": "Foco do relatÃ³rio."},
                        "frequencia": {"type": "string", "description": "'diariamente', 'semanalmente', 'mensalmente'."},
                        "hora": {"type": "string", "description": "Hora HH:MM."},
                        "timezone": {"type": "string", "description": "Fuso horÃ¡rio (padrÃ£o: America/Sao_Paulo)."},
                        "data_inicio": {
                            "type": "string", 
                            "description": "Data de inÃ­cio convertida EXCLUSIVAMENTE para o formato YYYY-MM-DD. Ex: se o usuÃ¡rio disser '04/11/2025' ou '4 de novembro', envie '2025-11-04'."
                        },
                        "data_fim": {
                            "type": "string", 
                            "description": "Data final convertida EXCLUSIVAMENTE para o formato YYYY-MM-DD. Calcule baseando-se na duraÃ§Ã£o se necessÃ¡rio."
                        }
                    },
                    "required": ["repositorio", "prompt_relatorio", "frequencia", "hora"]
                }
            }
        }
        
        self.tool_save_instruction = {
            "type": "function",
            "function": {
                "name": "call_save_instruction_tool",
                "description": "Salva instruÃ§Ã£o/template.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "repositorio": {"type": "string", "description": "URL ou nome do repositÃ³rio."},
                        "instrucao": {"type": "string", "description": "Texto da instruÃ§Ã£o."}
                    },
                    "required": ["repositorio", "instrucao"],
                },
            },
        }

        self.tool_chat = {
            "type": "function",
            "function": {
                "name": "call_chat_tool",
                "description": "Bate-papo casual.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "prompt": {"type": "string", "description": "Texto do usuÃ¡rio."}
                    },
                },
            },
        }

        self.tools = [
            self.tool_ingest,
            self.tool_query,
            self.tool_report,
            self.tool_send_onetime_report,
            self.tool_schedule,
            self.tool_save_instruction,
            self.tool_chat
        ]

        self.tool_map = {
            "call_ingest_tool": self.tool_ingest,
            "call_query_tool": self.tool_query,
            "call_report_tool": self.tool_report,
            "call_send_onetime_report_tool": self.tool_send_onetime_report,
            "call_schedule_tool": self.tool_schedule,
            "call_save_instruction_tool": self.tool_save_instruction,
            "call_chat_tool": self.tool_chat
        }

    def _handle_tool_call_args(self, tool_call: Dict[str, Any]) -> Dict[str, Any]:
        name = tool_call.get('function', {}).get('name')
        args = tool_call.get('function', {}).get('arguments', {})
        
        if name == "call_schedule_tool":
            if 'timezone' not in args or not args['timezone']:
                args['timezone'] = 'America/Sao_Paulo'
        
        # MantÃ©m a URL intacta para o GithubService processar a branch
        if 'repositorio' in args:
            print(f"[LLMService] RepositÃ³rio preservado (raw): {args['repositorio']}")

        return args

    def get_intent(self, user_query: str) -> Dict[str, Any]:
        if not self.client:
            raise Exception("LLMService nÃ£o inicializado")
        
        print(f"[LLMService] Roteando: '{user_query}'")
        
        system_prompt = f"""
VocÃª Ã© um roteador de intenÃ§Ãµes do GitRAG.

IMPORTANTE SOBRE REPOSITÃ“RIOS:
1. Se o usuÃ¡rio fornecer uma URL (ex: 'https://github.com/user/repo/tree/dev'), passe a URL COMPLETA como argumento.
2. Se fornecer apenas 'user/repo', use isso.
3. Se nÃ£o fornecer, deixe o campo vazio.

DECISÃƒO DE FERRAMENTAS:
- EMAIL AGORA -> call_send_onetime_report_tool
- AGENDAR -> call_schedule_tool
- DOWNLOAD/RELATÃ“RIO -> call_report_tool
- PERGUNTA SOBRE CÃ“DIGO -> call_query_tool
- INGESTÃƒO/ATUALIZAR -> call_ingest_tool
- PAPO FURADO -> call_chat_tool

Data Hoje: {datetime.now(pytz.timezone('America/Sao_Paulo')).strftime('%Y-%m-%d')}.
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.routing_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_query}
                ],
                tools=self.tools,
                tool_choice="auto" 
            )
            
            message = response.choices[0].message
            tool_calls = message.tool_calls

            if not tool_calls:
                return {
                    "type": "simple_chat", 
                    "response_text": message.content or "Entendido."
                }

            steps = []
            for call in tool_calls:
                try:
                    args = json.loads(call.function.arguments)
                    args_with_fallback = self._handle_tool_call_args({
                        'function': {'name': call.function.name, 'arguments': args}
                    })
                    steps.append({
                        "intent": call.function.name,
                        "args": args_with_fallback
                    })
                except json.JSONDecodeError:
                    return {"type": "clarify", "response_text": "Erro ao processar argumentos."}
            
            for step in steps:
                if step["intent"] != "call_chat_tool":
                    required = self.tool_map[step["intent"]]["function"]["parameters"]["required"]
                    for param in required:
                        if not step["args"].get(param): 
                            return {
                                "type": "clarify",
                                "response_text": f"Preciso que vocÃª informe o {param}."
                            }

            return {"type": "multi_step", "steps": steps}

        except Exception as e:
            print(f"[LLMService] Erro: {e}")
            return {"type": "clarify", "response_text": f"Erro interno: {e}"}

    # --- MÃ‰TODOS DE GERAÃ‡ÃƒO RAG (NOVOS) ---
    def generate_rag_response_stream(
        self, 
        contexto: str, 
        prompt: str, 
        instrucao_rag: Optional[str] = None
    ) -> Iterator[str]:
        """
        Gera resposta RAG via stream com formataÃ§Ã£o de links garantida.
        """
        if not self.client: raise Exception("LLMService nÃ£o inicializado.")
        
        # --- PROMPT DO SISTEMA REFORÃ‡ADO PARA LINKS ---
        system_content = """VocÃª Ã© um assistente especializado em anÃ¡lise de cÃ³digo (GitRAG).

DIRETRIZES OBRIGATÃ“RIAS DE FORMATAÃ‡ÃƒO:
1. CITAÃ‡Ã•ES CLICÃVEIS: Sempre que citar um Commit, Issue ou Pull Request, vocÃª DEVE formatÃ¡-lo como um link Markdown usando a URL fornecida no contexto.
   - Formato para Commits: `[SHA_CURTO](URL_DO_GITHUB)`
   - Formato para Issues/PRs: `[#NUMERO](URL_DO_GITHUB)`
   - Exemplo: "A correÃ§Ã£o foi feita no commit [a1b2c3d](https://github.com/...)."

2. PRECISÃƒO: Use exatamente os dados fornecidos no bloco de contexto. NÃ£o invente links.
"""
        if instrucao_rag:
            system_content += f"\n\nInstruÃ§Ã£o Especial do UsuÃ¡rio:\n{instrucao_rag}"
            
        user_content = f"""Com base EXCLUSIVAMENTE no contexto abaixo, responda Ã  pergunta.

--- CONTEXTO INÃCIO ---
{contexto}
--- CONTEXTO FIM ---

Pergunta do UsuÃ¡rio: {prompt}
"""
        try:
            stream = self.client.chat.completions.create(
                model=self.generation_model,
                messages=[
                    {"role": "system", "content": system_content},
                    {"role": "user", "content": user_content}
                ], 
                stream=True, 
                temperature=0.2 
            )
            for chunk in stream:
                content = chunk.choices[0].delta.content
                if content: yield content
        except Exception as e:
            yield f"Erro na geraÃ§Ã£o stream: {e}"

    def generate_rag_response(
        self, 
        contexto: str, 
        prompt: str, 
        instrucao_rag: Optional[str] = None
    ) -> str:
        """
        VersÃ£o sÃ­ncrona da resposta RAG.
        """
        full_response = ""
        for chunk in self.generate_rag_response_stream(contexto, prompt, instrucao_rag):
            full_response += chunk
        return full_response

    # --- MÃ‰TODOS LEGADOS / UTILITÃRIOS ---
    def generate_analytics_report(self, repo_name: str, user_prompt: str, raw_data: List[Dict[str, Any]]) -> str:
        # Converte apenas os campos necessÃ¡rios para economizar tokens
        # Se o raw_data for muito grande, isso pode estourar o contexto.
        # Idealmente, aqui farÃ­amos um resumo, mas para TCC serve.
        simplified_data = []
        for item in raw_data:
            if item.get('tipo') in ['commit', 'issue', 'pr']:
                simplified_data.append({'tipo': item['tipo'], 'meta': item.get('metadados')})
            else:
                # Arquivos: truncamos o conteÃºdo
                content = item.get('conteudo', '')[:200] + "..."
                simplified_data.append({'tipo': 'file', 'path': item.get('file_path'), 'content_snippet': content})
                
        context_json = json.dumps(simplified_data)
        
        try:
            response = self.client.chat.completions.create(
                model=self.generation_model, 
                messages=[
                    {"role": "system", "content": "Gere um JSON com 'analysis_markdown' e 'chart_json'."},
                    {"role": "user", "content": f"Repo: {repo_name}\nPrompt: {user_prompt}\nDados: {context_json}"}
                ],
                response_format={"type": "json_object"}, temperature=0.3, max_tokens=4000
            )
            return response.choices[0].message.content
        except Exception as e: return json.dumps({"analysis_markdown": f"Erro: {e}", "chart_json": None})

    def generate_simple_response(self, prompt: str) -> str:
        try:
            response = self.client.chat.completions.create(
                model=self.routing_model, 
                messages=[{"role": "system", "content": "Seja breve."}, {"role": "user", "content": prompt}],
                temperature=0.3, max_tokens=50
            )
            return response.choices[0].message.content
        except Exception: return "ğŸ‘"

    def get_token_usage(self) -> Dict[str, int]: return self.token_usage
    
    def _format_requirements_data(self, requirements_data: List[Dict[str, Any]]) -> str:
        return json.dumps(requirements_data, indent=2, ensure_ascii=False) if requirements_data else "Sem dados."

    def _format_context(self, context: List[Dict[str, Any]]) -> str:
        return "\n".join([f"---\nConteÃºdo: {doc.get('conteudo', doc.get('text', ''))}" for doc in context]) if context else "Nenhum contexto."

    def summarize_plan_for_confirmation(self, steps: List[Dict[str, Any]], user_email: str) -> str:
        plan_text = ""
        for step in steps:
            intent = step['intent'].replace('call_', '').replace('_tool', '')
            args = step['args']
            repo = args.get('repositorio', 'N/A')
            plan_text += f"* AÃ§Ã£o: {intent} em {repo}\n"
            
        return f"**Plano:**\n{plan_text}\n**Confirma?** (Sim/NÃ£o)"

    def summarize_action_for_confirmation(self, intent_name: str, args: Dict[str, Any]) -> str:
        return f"Confirmar: {intent_name}?"